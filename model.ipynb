{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPwOGZnkslmTSgDxsNj4CsB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shyDaniel/PM2.5_prediction_regression/blob/master/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7TeA9Q1qt95",
        "colab_type": "text"
      },
      "source": [
        "# **PREDICTING PM2.5 WITH LINEAR REGRESSION, TECHINIQUES INCLUDING FEATURE ENGINEERING, CROSS-VALIDATION, NORMALIZATION, AND ADAGRAD GRADIENT OPTIMIZATION.**\n",
        "\n",
        "Kaggle: https://www.kaggle.com/c/ml2020spring-hw1/overview\n",
        "\n",
        "Hanyu Song 03/19/2020"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYrq3fUsb0tm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "90fe3fa6-dff2-4a61-a55a-d6da8fd82971"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "# import train data from google drive\n",
        "! gdown --id '1VR_MKDGwhexEThy4VEZudoN0zKgNRpys'\n",
        "train = pd.read_csv('./train.csv', encoding = 'big5')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1VR_MKDGwhexEThy4VEZudoN0zKgNRpys\n",
            "To: /content/train.csv\n",
            "\r  0% 0.00/466k [00:00<?, ?B/s]\r100% 466k/466k [00:00<00:00, 67.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDLB4UZiHbt2",
        "colab_type": "text"
      },
      "source": [
        "## **FEATURE ENGINEERING FOR TRAINING DATASET**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ApB6JLyuIfc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# delete unnecessary columns, fill in NR values, change to numpy form\n",
        "train = train.iloc[:, 3:]\n",
        "train[train == 'NR'] = 0\n",
        "train_data = train.to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPPZzHpjHfS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now split train data into 12 (months) blocks in which each block contains 18 (features )*480 (24 hours * 20 days) info\n",
        "monthly_train = {}\n",
        "for month in range(12):\n",
        "  temp = np.empty((18, 480))\n",
        "  for day in range(20):\n",
        "    temp[:, day*24 : (day + 1)*24] = train_data[18 * (20*month + day) : 18 * (20 * month + day + 1), :]\n",
        "  monthly_train[month] = temp;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXXJAyfEQJSC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we will use previous 9 hours to data to predict the next, which is the 10th hour of pm2.5 level. \n",
        "# Therefore, out of the 480 hours we have for a given month, we have 471 sets of data (480 - 9) that can be used for training.\n",
        "# y shape: (12*471) * 1\n",
        "# x shape: (12*471) * (9*18)\n",
        "# weight shape: (9*18) * 1\n",
        "# y = x*w\n",
        "\n",
        "x = np.empty((12*471, 9*18), dtype = float)\n",
        "y = np.empty((12*471, 1), dtype = float)\n",
        "\n",
        "for month in range(12):\n",
        "  for day in range(20):\n",
        "    for hour in range(24):\n",
        "      if day == 0 and hour < 9:\n",
        "          continue\n",
        "      y[month * 471 + day * 24 + hour - 9, 0] = monthly_train[month][9, day * 24 + hour] #PM2.5 is on row 9\n",
        "\n",
        "for month in range(12):\n",
        "  for day in range(20):\n",
        "    for hour in range(24):\n",
        "      if day == 19 and hour > 14: \n",
        "        continue\n",
        "      x[month * 471 + day * 24 + hour, :] = monthly_train[month][:, day * 24 + hour : day * 24 + hour + 9].reshape(1, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNP6ekTSHnRr",
        "colab_type": "text"
      },
      "source": [
        "## **NORMALIZATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEzkzU6lF1SZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for each of the 18 features, compute their mean and std \n",
        "# then use newdata = (data - mean) /std to update x\n",
        "mean_x = np.mean(x, axis = 0) #18 * 9 \n",
        "std_x = np.std(x, axis = 0) #18 * 9 \n",
        "normed_x = np.empty(x.shape, dtype = float)\n",
        "for i in range(len(x)): #12 * 471\n",
        "    for j in range(len(x[0])): #18 * 9 \n",
        "        if std_x[j] != 0:\n",
        "            normed_x[i][j] = (x[i][j] - mean_x[j]) / std_x[j]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knF_dm5ha088",
        "colab_type": "text"
      },
      "source": [
        "## **CROSS-VALIDATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6YkjojRaz2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is an illustration of how we would split dataset into 4:1 train and validate\n",
        "# x_train_set = x[: math.floor(len(normed_x) * 0.8), :]\n",
        "# y_train_set = y[: math.floor(len(y) * 0.8), :]\n",
        "# x_validation = x[math.floor(len(normed_x) * 0.8): , :]\n",
        "# y_validation = y[math.floor(len(y) * 0.8): , :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nehvGmDK8d9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import random as rand\n",
        "\n",
        "dim = 9 * 18 + 1 # 9 * 18 features with 1 more constant\n",
        "learning_rate = 100\n",
        "iter_time = 10000\n",
        "adagrad = np.zeros([dim, 1])\n",
        "eps = 0.0000000001\n",
        "sum_loss = 0\n",
        "k_fold = 5\n",
        "\n",
        "# Do 5-fold cross-validation on the normed_x and y\n",
        "for i in range(k_fold):\n",
        "  w = np.zeros((dim, 1))\n",
        "  # create training and validating data for each iteration\n",
        "  x_train_set = np.concatenate((normed_x[: math.floor(len(normed_x) * (0.2*i)), :], normed_x[math.floor(len(normed_x) * 0.2*(i + 1)) :, :]))\n",
        "  x_validate_set = normed_x[math.floor(len(normed_x) * (0.2*i)) : math.floor(len(normed_x) * 0.2* (i + 1))]\n",
        "  y_train_set = np.concatenate((y[:math.floor(len(y) * (0.2*i)), :], y[math.floor(len(y) * 0.2*(i + 1)):, :]))\n",
        "  y_validate_set = y[math.floor(len(y) * (0.2*i)) : math.floor(len(y) * 0.2* (i + 1))]\n",
        " \n",
        "  # x train plus one row of constant (to test the weight for the constant term)\n",
        "  temp_x = np.concatenate((np.ones((x_train_set.shape[0], 1)), x_train_set), axis = 1)\n",
        "  x_validate_set = np.concatenate((np.ones((x_validate_set.shape[0], 1)), x_validate_set), axis = 1)\n",
        "  gradient = np.zeros((dim, 1))\n",
        "\n",
        "  for t in range(iter_time):\n",
        "    loss = np.sqrt(np.sum(np.power(np.dot(temp_x, w) - y_train_set, 2))/471/12)#rmse\n",
        "    if(t%1000==0):\n",
        "        print(\"  \" + str(t) + \":\" + str(loss))\n",
        "    # gradient descent\n",
        "    gradient = 2 * np.dot(temp_x.transpose(), np.dot(temp_x, w) - y_train_set) #dim*1\n",
        "\n",
        "    # if (gradient){\n",
        "    #     break;\n",
        "    # }\n",
        "\n",
        "    #adagrad gradient optimization\n",
        "    adagrad += gradient ** 2\n",
        "    w = w - learning_rate * gradient / np.sqrt(adagrad + eps)\n",
        "  \n",
        "  final_w += w\n",
        "  print(\"for the \", i,\"th time, the parameter is roughly \", w[rand.randrange(1,18),0])\n",
        "  valid_loss = np.sqrt(np.sum(np.power(np.dot(x_validate_set, w) - y_validate_set, 2))/471/12)\n",
        "  print(\"the loss for the \", i,\"th time validate is \", valid_loss)\n",
        "  sum_loss += valid_loss\n",
        "\n",
        "print('average loss for the 5-fold validation is: ', sum_loss/k_fold)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dBshXDetkfm",
        "colab_type": "text"
      },
      "source": [
        "## **TRAINING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZXdK7Aptegk",
        "colab_type": "code",
        "outputId": "091a4c9e-bac3-4059-ee00-7ee608b60576",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "dim = 9 * 18 + 1 # 9 * 18 features with 1 more constant\n",
        "learning_rate = 0.3\n",
        "# iter_time = 5000\n",
        "t = 0\n",
        "oldloss = 1\n",
        "newloss = 1\n",
        "adagrad = np.zeros([dim, 1])\n",
        "eps = 0.0000000001\n",
        "w = np.random.rand(dim ,1)\n",
        "normed_x1 = np.concatenate((np.ones([12 * 471, 1]), normed_x), axis = 1)\n",
        "\n",
        "while True:\n",
        "    oldloss = newloss\n",
        "    loss = np.sqrt(np.sum(np.power(np.dot(normed_x1, w) - y, 2))/471/12)#rmse\n",
        "    newloss = loss\n",
        "    if (abs((newloss - oldloss)/oldloss) < 0.0000008):\n",
        "      break;\n",
        "    if(t%1000==0):\n",
        "        print(str(t) + \":\" + str(loss))\n",
        "    gradient = 2 * np.dot(normed_x1.transpose(), np.dot(normed_x1, w) - y) #dim*1\n",
        "    adagrad += gradient ** 2\n",
        "    w = w - learning_rate * gradient / np.sqrt(adagrad + eps)\n",
        "    t = t + 1\n",
        "np.save('model_weights.npy', w)\n",
        "w"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0:30.347609310640646\n",
            "1000:8.734215453347323\n",
            "2000:6.443463205915888\n",
            "3000:5.867558261495341\n",
            "4000:5.729875927482143\n",
            "5000:5.696009969243451\n",
            "6000:5.68680290754431\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2.12490347e+01],\n",
              "       [ 3.36594720e-01],\n",
              "       [-5.46746148e-01],\n",
              "       [ 5.69629374e-01],\n",
              "       [-1.37026123e+00],\n",
              "       [ 1.53012825e-01],\n",
              "       [ 7.18439260e-01],\n",
              "       [-4.53795246e-01],\n",
              "       [-1.29188340e+00],\n",
              "       [ 1.78546046e+00],\n",
              "       [-3.29298805e-01],\n",
              "       [ 1.41828540e-01],\n",
              "       [ 6.35711811e-02],\n",
              "       [ 1.10033269e-01],\n",
              "       [-2.86264263e-02],\n",
              "       [-3.90982434e-02],\n",
              "       [-1.65993242e-01],\n",
              "       [ 1.64986734e-01],\n",
              "       [ 5.24532911e-01],\n",
              "       [ 5.38425432e-02],\n",
              "       [-2.28782655e-02],\n",
              "       [ 6.32837060e-02],\n",
              "       [-1.54997641e-01],\n",
              "       [ 1.52672583e-01],\n",
              "       [-2.27534686e-02],\n",
              "       [-1.66620253e-01],\n",
              "       [ 8.30548944e-02],\n",
              "       [ 4.06962639e-01],\n",
              "       [-3.21995170e-01],\n",
              "       [ 3.67557006e-01],\n",
              "       [-2.57704067e-01],\n",
              "       [ 3.11956117e-01],\n",
              "       [ 2.89220524e-01],\n",
              "       [-5.17354652e-01],\n",
              "       [ 1.17305777e-01],\n",
              "       [ 1.51924401e-01],\n",
              "       [ 1.06038609e-01],\n",
              "       [-5.51793133e-03],\n",
              "       [ 1.30132323e-02],\n",
              "       [ 2.66489480e-01],\n",
              "       [-2.55771438e-01],\n",
              "       [-1.19330691e-01],\n",
              "       [-2.26402003e-01],\n",
              "       [ 2.51457251e-02],\n",
              "       [ 8.27345601e-03],\n",
              "       [-4.47611308e-01],\n",
              "       [ 4.75558879e-02],\n",
              "       [-4.16996017e-01],\n",
              "       [-1.17674028e-01],\n",
              "       [-7.10913458e-01],\n",
              "       [-4.81964243e-01],\n",
              "       [-8.83293116e-02],\n",
              "       [-4.40600150e-01],\n",
              "       [-1.23557273e+00],\n",
              "       [ 8.59990556e-01],\n",
              "       [ 2.79198238e-01],\n",
              "       [-1.59047225e-01],\n",
              "       [ 3.34226943e-02],\n",
              "       [ 6.58361899e-01],\n",
              "       [ 4.55522295e-01],\n",
              "       [ 1.86198494e-01],\n",
              "       [ 1.11033532e-01],\n",
              "       [ 8.04603605e-01],\n",
              "       [ 1.08799002e+00],\n",
              "       [-3.85138489e-03],\n",
              "       [ 2.76313976e-01],\n",
              "       [-2.09088508e-01],\n",
              "       [-3.46518878e-01],\n",
              "       [ 1.97838947e-02],\n",
              "       [-6.41128915e-01],\n",
              "       [-3.53332387e-01],\n",
              "       [-3.12617638e-01],\n",
              "       [ 1.90020657e+00],\n",
              "       [ 2.64064844e-01],\n",
              "       [ 9.59145818e-02],\n",
              "       [-6.41483084e-01],\n",
              "       [ 1.13683562e+00],\n",
              "       [-4.39756331e-01],\n",
              "       [-8.00443947e-01],\n",
              "       [ 1.01070270e+00],\n",
              "       [-2.44925727e-01],\n",
              "       [ 1.08668018e+00],\n",
              "       [-6.83510360e-01],\n",
              "       [ 4.79811084e-02],\n",
              "       [ 3.32556760e+00],\n",
              "       [-3.98494538e+00],\n",
              "       [ 1.01960825e-01],\n",
              "       [ 7.72499373e+00],\n",
              "       [-9.27561287e+00],\n",
              "       [ 9.52990784e-01],\n",
              "       [ 1.53891358e+01],\n",
              "       [ 7.41227452e-02],\n",
              "       [-1.73037328e-02],\n",
              "       [-9.54545315e-02],\n",
              "       [ 1.90637203e-02],\n",
              "       [-1.11472598e-01],\n",
              "       [ 1.07011200e-01],\n",
              "       [ 3.40631056e-02],\n",
              "       [-8.03143600e-02],\n",
              "       [-1.63914816e-01],\n",
              "       [-1.54721921e-01],\n",
              "       [ 4.04217618e-01],\n",
              "       [ 1.32765257e-01],\n",
              "       [-7.67482487e-01],\n",
              "       [-4.77312797e-01],\n",
              "       [ 9.78252121e-01],\n",
              "       [-1.24534004e+00],\n",
              "       [ 1.11397622e-01],\n",
              "       [ 6.30404364e-01],\n",
              "       [-5.18975819e-01],\n",
              "       [ 6.10399985e-01],\n",
              "       [-1.26057274e-01],\n",
              "       [-1.04828599e-01],\n",
              "       [-1.45268308e-02],\n",
              "       [ 9.31777124e-02],\n",
              "       [-1.94170148e-01],\n",
              "       [ 2.49226750e-01],\n",
              "       [ 2.72560966e-01],\n",
              "       [ 3.57790173e-01],\n",
              "       [-2.97112648e-01],\n",
              "       [ 1.55538403e-01],\n",
              "       [-4.50390933e-01],\n",
              "       [-4.92932627e-02],\n",
              "       [ 3.63539760e-01],\n",
              "       [ 4.59349570e-02],\n",
              "       [-3.51897319e-01],\n",
              "       [-1.63052078e-01],\n",
              "       [-4.20733071e-02],\n",
              "       [ 2.81317448e-01],\n",
              "       [-3.99791490e-02],\n",
              "       [ 1.81280131e-01],\n",
              "       [ 4.33703950e-02],\n",
              "       [ 1.59740104e-01],\n",
              "       [-2.49406146e-01],\n",
              "       [ 1.14715462e-01],\n",
              "       [ 2.95964426e-02],\n",
              "       [-1.93890273e-01],\n",
              "       [-9.36930787e-02],\n",
              "       [ 8.60705382e-02],\n",
              "       [-1.78738072e-01],\n",
              "       [ 4.41933909e-02],\n",
              "       [ 1.24288707e-02],\n",
              "       [-1.14385400e-03],\n",
              "       [-2.31556228e-01],\n",
              "       [ 4.80470169e-02],\n",
              "       [-1.90458148e-01],\n",
              "       [-1.37397611e-01],\n",
              "       [ 2.63305471e-01],\n",
              "       [ 8.88541257e-02],\n",
              "       [-1.06372061e-01],\n",
              "       [-8.66969111e-02],\n",
              "       [-3.90485956e-02],\n",
              "       [-1.42081956e-02],\n",
              "       [-1.43704448e-01],\n",
              "       [-1.89032951e-02],\n",
              "       [ 1.94696744e-01],\n",
              "       [-1.57323755e-01],\n",
              "       [-2.47647561e-01],\n",
              "       [-4.50790312e-02],\n",
              "       [ 3.60996346e-01],\n",
              "       [-1.04383523e-02],\n",
              "       [-3.29023944e-01],\n",
              "       [ 2.14687018e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xs284OejTilx",
        "colab_type": "text"
      },
      "source": [
        "## **FEATURE ENGINEERING FOR TESTING DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jdgrni-TiIq",
        "colab_type": "code",
        "outputId": "6f0fbdc3-6984-460c-cb44-8d09e9542a02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "! gdown --id '1JnF9biNzFqx5_9RKzCKPKgHPggtDHhue'\n",
        "test = pd.read_csv('./test.csv', encoding = 'big5')\n",
        "test = test.iloc[:, 2:]\n",
        "test[test == 'NR'] = 0\n",
        "test = test.to_numpy()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1JnF9biNzFqx5_9RKzCKPKgHPggtDHhue\n",
            "To: /content/test.csv\n",
            "\r  0% 0.00/197k [00:00<?, ?B/s]\r100% 197k/197k [00:00<00:00, 68.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rk43DF45bWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# noticed that test data lacked the first row of data, which is AMB_TEMP, manually fill them up\n",
        "add = np.empty((1,9))\n",
        "add[0] = [21, 21, 20, 20, 19, 19, 19, 18, 17]\n",
        "test = np.concatenate((add,test), axis = 0)\n",
        "test_x = np.empty([240, 18*9], dtype = float)\n",
        "for i in range(240):\n",
        "    test_x[i, :] = test[18 * i: 18* (i + 1), :].reshape(1, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BK8FCa_4g11a",
        "colab_type": "text"
      },
      "source": [
        "## **NORMALIZATION FOR TESTING DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJ_laKAag0DJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(test_x)):\n",
        "    for j in range(len(test_x[0])):\n",
        "        if std_x[j] != 0:\n",
        "            test_x[i][j] = (test_x[i][j] - mean_x[j]) / std_x[j]\n",
        "normed_test_x = np.concatenate((np.ones([240, 1]), test_x), axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGi6UiEUkYQn",
        "colab_type": "text"
      },
      "source": [
        "## **PREDICTION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txt6tH7MkXwX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_w = np.load('model_weights.npy')\n",
        "ans_y = np.dot(normed_test_x, test_w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toxmjS1IkokP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame(np.empty((240, 2)), index = np.arange(240) + 1, columns = ['id', 'value'])\n",
        "for i in range(240):\n",
        "  df.iloc[i, 0] = 'id_' + str(i)\n",
        "  df.iloc[i,1] = ans_y[i][0]\n",
        "df.to_csv('submission.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}