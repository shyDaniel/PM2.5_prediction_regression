{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOtlyN8l1I+TuSTIL9sAuR5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shyDaniel/PM2.5_prediction_regression/blob/master/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7TeA9Q1qt95",
        "colab_type": "text"
      },
      "source": [
        "# **PREDICTING PM2.5 WITH LINEAR REGRESSION, TECHINIQUES INCLUDING FEATURE ENGINEERING, CROSS-VALIDATION, NORMALIZATION, AND ADAGRAD GRADIENT OPTIMIZATION.**\n",
        "\n",
        "Kaggle: https://www.kaggle.com/c/ml2020spring-hw1/overview\n",
        "\n",
        "Hanyu Song 03/19/2020"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYrq3fUsb0tm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "# import train data from google drive\n",
        "! gdown --id '1VR_MKDGwhexEThy4VEZudoN0zKgNRpys'\n",
        "train = pd.read_csv('./train.csv', encoding = 'big5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDLB4UZiHbt2",
        "colab_type": "text"
      },
      "source": [
        "## **FEATURE ENGINEERING FOR TRAINING DATASET**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ApB6JLyuIfc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# delete unnecessary columns, fill in NR values, change to numpy form\n",
        "train = train.iloc[:, 3:]\n",
        "train[train == 'NR'] = 0\n",
        "train_data = train.to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPPZzHpjHfS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now split train data into 12 (months) blocks in which each block contains 18 (features )*480 (24 hours * 20 days) info\n",
        "monthly_train = {}\n",
        "for month in range(12):\n",
        "  temp = np.empty((18, 480))\n",
        "  for day in range(20):\n",
        "    temp[:, day*24 : (day + 1)*24] = train_data[18 * (20*month + day) : 18 * (20 * month + day + 1), :]\n",
        "  monthly_train[month] = temp;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXXJAyfEQJSC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we will use previous 9 hours to data to predict the next, which is the 10th hour of pm2.5 level. \n",
        "# Therefore, out of the 480 hours we have for a given month, we have 471 sets of data (480 - 9) that can be used for training.\n",
        "# y shape: (12*471) * 1\n",
        "# x shape: (12*471) * (9*18)\n",
        "# weight shape: (9*18) * 1\n",
        "# y = x*w\n",
        "\n",
        "x = np.empty((12*471, 9*18), dtype = float)\n",
        "y = np.empty((12*471, 1), dtype = float)\n",
        "\n",
        "for month in range(12):\n",
        "  for day in range(20):\n",
        "    for hour in range(24):\n",
        "      if day == 0 and hour < 9:\n",
        "          continue\n",
        "      y[month * 471 + day * 24 + hour - 9, 0] = monthly_train[month][9, day * 24 + hour] #PM2.5 is on row 9\n",
        "\n",
        "for month in range(12):\n",
        "  for day in range(20):\n",
        "    for hour in range(24):\n",
        "      if day == 19 and hour > 14: \n",
        "        continue\n",
        "      x[month * 471 + day * 24 + hour, :] = monthly_train[month][:, day * 24 + hour : day * 24 + hour + 9].reshape(1, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNP6ekTSHnRr",
        "colab_type": "text"
      },
      "source": [
        "## **NORMALIZATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEzkzU6lF1SZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for each of the 18 features, compute their mean and std \n",
        "# then use newdata = (data - mean) /std to update x\n",
        "mean_x = np.mean(x, axis = 0) #18 * 9 \n",
        "std_x = np.std(x, axis = 0) #18 * 9 \n",
        "normed_x = np.empty(x.shape, dtype = float)\n",
        "for i in range(len(x)): #12 * 471\n",
        "    for j in range(len(x[0])): #18 * 9 \n",
        "        if std_x[j] != 0:\n",
        "            normed_x[i][j] = (x[i][j] - mean_x[j]) / std_x[j]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knF_dm5ha088",
        "colab_type": "text"
      },
      "source": [
        "## **CROSS-VALIDATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6YkjojRaz2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is an illustration of how we would split dataset into 4:1 train and validate\n",
        "# x_train_set = x[: math.floor(len(normed_x) * 0.8), :]\n",
        "# y_train_set = y[: math.floor(len(y) * 0.8), :]\n",
        "# x_validation = x[math.floor(len(normed_x) * 0.8): , :]\n",
        "# y_validation = y[math.floor(len(y) * 0.8): , :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nehvGmDK8d9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import random as rand\n",
        "\n",
        "dim = 9 * 18 + 1 # 9 * 18 features with 1 more constant\n",
        "learning_rate = 100\n",
        "iter_time = 10000\n",
        "adagrad = np.zeros([dim, 1])\n",
        "eps = 0.0000000001\n",
        "sum_loss = 0\n",
        "k_fold = 5\n",
        "\n",
        "# Do 5-fold cross-validation on the normed_x and y\n",
        "for i in range(k_fold):\n",
        "  w = np.zeros((dim, 1))\n",
        "  # create training and validating data for each iteration\n",
        "  x_train_set = np.concatenate((normed_x[: math.floor(len(normed_x) * (0.2*i)), :], normed_x[math.floor(len(normed_x) * 0.2*(i + 1)) :, :]))\n",
        "  x_validate_set = normed_x[math.floor(len(normed_x) * (0.2*i)) : math.floor(len(normed_x) * 0.2* (i + 1))]\n",
        "  y_train_set = np.concatenate((y[:math.floor(len(y) * (0.2*i)), :], y[math.floor(len(y) * 0.2*(i + 1)):, :]))\n",
        "  y_validate_set = y[math.floor(len(y) * (0.2*i)) : math.floor(len(y) * 0.2* (i + 1))]\n",
        " \n",
        "  # x train plus one row of constant (to test the weight for the constant term)\n",
        "  temp_x = np.concatenate((np.ones((x_train_set.shape[0], 1)), x_train_set), axis = 1)\n",
        "  x_validate_set = np.concatenate((np.ones((x_validate_set.shape[0], 1)), x_validate_set), axis = 1)\n",
        "  gradient = np.zeros((dim, 1))\n",
        "\n",
        "  for t in range(iter_time):\n",
        "    loss = np.sqrt(np.sum(np.power(np.dot(temp_x, w) - y_train_set, 2))/471/12)#rmse\n",
        "    if(t%1000==0):\n",
        "        print(\"  \" + str(t) + \":\" + str(loss))\n",
        "    # gradient descent\n",
        "    gradient = 2 * np.dot(temp_x.transpose(), np.dot(temp_x, w) - y_train_set) #dim*1\n",
        "\n",
        "    # if (gradient){\n",
        "    #     break;\n",
        "    # }\n",
        "\n",
        "    #adagrad gradient optimization\n",
        "    adagrad += gradient ** 2\n",
        "    w = w - learning_rate * gradient / np.sqrt(adagrad + eps)\n",
        "  \n",
        "  final_w += w\n",
        "  print(\"for the \", i,\"th time, the parameter is roughly \", w[rand.randrange(1,18),0])\n",
        "  valid_loss = np.sqrt(np.sum(np.power(np.dot(x_validate_set, w) - y_validate_set, 2))/471/12)\n",
        "  print(\"the loss for the \", i,\"th time validate is \", valid_loss)\n",
        "  sum_loss += valid_loss\n",
        "\n",
        "print('average loss for the 5-fold validation is: ', sum_loss/k_fold)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dBshXDetkfm",
        "colab_type": "text"
      },
      "source": [
        "## **TRAINING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZXdK7Aptegk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5dc98209-8deb-4440-9d06-b25a5e6777d3"
      },
      "source": [
        "dim = 9 * 18 + 1 # 9 * 18 features with 1 more constant\n",
        "learning_rate = 0.3\n",
        "# iter_time = 5000\n",
        "t = 0\n",
        "oldloss = 1\n",
        "newloss = 1\n",
        "adagrad = np.zeros([dim, 1])\n",
        "eps = 0.0000000001\n",
        "w = np.zeros([dim, 1])\n",
        "normed_x1 = np.concatenate((np.ones([12 * 471, 1]), normed_x), axis = 1)\n",
        "\n",
        "while True:\n",
        "    oldloss = newloss\n",
        "    loss = np.sqrt(np.sum(np.power(np.dot(normed_x1, w) - y, 2))/471/12)#rmse\n",
        "    newloss = loss\n",
        "    if (abs((newloss - oldloss)/oldgrad) < 0.000008):\n",
        "      break;\n",
        "    if(t%1000==0):\n",
        "        print(str(t) + \":\" + str(loss))\n",
        "    gradient = 2 * np.dot(normed_x1.transpose(), np.dot(normed_x1, w) - y) #dim*1\n",
        "    adagrad += gradient ** 2\n",
        "    w = w - learning_rate * gradient / np.sqrt(adagrad + eps)\n",
        "    t = t + 1\n",
        "np.save('model_weights.npy', w)\n",
        "w"
      ],
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0:27.071214829194115\n",
            "1000:8.913283834966617\n",
            "2000:6.543698671195583\n",
            "3000:5.9152351138423045\n",
            "4000:5.75212410714295\n",
            "5000:5.706817636905021\n",
            "6000:5.692298841568733\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2.12397876e+01],\n",
              "       [ 3.46300069e-01],\n",
              "       [-6.31635928e-01],\n",
              "       [ 8.02716662e-01],\n",
              "       [-1.63432592e+00],\n",
              "       [ 2.08487092e-01],\n",
              "       [ 8.74833057e-01],\n",
              "       [-5.16025604e-01],\n",
              "       [-1.46164933e+00],\n",
              "       [ 1.90770898e+00],\n",
              "       [-3.22000945e-01],\n",
              "       [ 1.39864345e-01],\n",
              "       [ 5.59171201e-02],\n",
              "       [ 1.22121439e-01],\n",
              "       [-3.51217603e-02],\n",
              "       [-4.74391723e-02],\n",
              "       [-1.61234293e-01],\n",
              "       [ 1.65920663e-01],\n",
              "       [ 5.30627050e-01],\n",
              "       [ 5.51889703e-02],\n",
              "       [-2.34531365e-02],\n",
              "       [ 6.15978411e-02],\n",
              "       [-1.49509250e-01],\n",
              "       [ 1.50218094e-01],\n",
              "       [-2.58828207e-02],\n",
              "       [-1.66949234e-01],\n",
              "       [ 8.66077949e-02],\n",
              "       [ 4.09472400e-01],\n",
              "       [-3.09140743e-01],\n",
              "       [ 3.54997995e-01],\n",
              "       [-2.61492976e-01],\n",
              "       [ 3.38499855e-01],\n",
              "       [ 2.69515588e-01],\n",
              "       [-5.16548888e-01],\n",
              "       [ 1.20616799e-01],\n",
              "       [ 1.44941901e-01],\n",
              "       [ 1.15167423e-01],\n",
              "       [ 8.60363219e-02],\n",
              "       [ 6.96422105e-02],\n",
              "       [ 2.18093859e-01],\n",
              "       [-2.91672997e-01],\n",
              "       [-1.11158711e-01],\n",
              "       [-2.75555540e-01],\n",
              "       [ 2.94066602e-02],\n",
              "       [ 8.77949370e-02],\n",
              "       [-4.41413044e-01],\n",
              "       [ 2.92582173e-01],\n",
              "       [-2.66137366e-01],\n",
              "       [-2.59374499e-01],\n",
              "       [-8.04894652e-01],\n",
              "       [-4.43038997e-01],\n",
              "       [-2.21460041e-01],\n",
              "       [-4.57891196e-01],\n",
              "       [-1.03695910e+00],\n",
              "       [ 9.22275293e-01],\n",
              "       [-2.45133048e-02],\n",
              "       [-3.43431464e-01],\n",
              "       [ 1.96021567e-01],\n",
              "       [ 7.79496673e-01],\n",
              "       [ 4.08992964e-01],\n",
              "       [ 3.49057028e-01],\n",
              "       [ 1.19405638e-01],\n",
              "       [ 5.55572430e-01],\n",
              "       [ 1.03811826e+00],\n",
              "       [ 4.33557967e-03],\n",
              "       [ 2.71003048e-01],\n",
              "       [-2.26897497e-01],\n",
              "       [-3.26712561e-01],\n",
              "       [-3.58212424e-03],\n",
              "       [-6.29002502e-01],\n",
              "       [-3.55297060e-01],\n",
              "       [-3.38733960e-01],\n",
              "       [ 1.94191524e+00],\n",
              "       [ 2.52677839e-01],\n",
              "       [ 2.40024535e-02],\n",
              "       [-4.79579532e-01],\n",
              "       [ 1.05403982e+00],\n",
              "       [-5.63626061e-01],\n",
              "       [-5.84825591e-01],\n",
              "       [ 9.26513149e-01],\n",
              "       [-3.58752614e-01],\n",
              "       [ 1.22517499e+00],\n",
              "       [-7.00474348e-01],\n",
              "       [ 2.28862897e-01],\n",
              "       [ 3.02010074e+00],\n",
              "       [-3.86355234e+00],\n",
              "       [ 4.13919923e-01],\n",
              "       [ 7.23221833e+00],\n",
              "       [-9.10953626e+00],\n",
              "       [ 1.28286857e+00],\n",
              "       [ 1.50541834e+01],\n",
              "       [ 7.36053160e-02],\n",
              "       [-1.79441661e-02],\n",
              "       [-9.15622613e-02],\n",
              "       [ 1.26834269e-02],\n",
              "       [-1.09794171e-01],\n",
              "       [ 1.11808312e-01],\n",
              "       [ 3.04760986e-02],\n",
              "       [-8.09323920e-02],\n",
              "       [-1.64044969e-01],\n",
              "       [-1.54755477e-01],\n",
              "       [ 4.09547091e-01],\n",
              "       [ 1.44772468e-01],\n",
              "       [-8.08388274e-01],\n",
              "       [-4.74636411e-01],\n",
              "       [ 1.03323831e+00],\n",
              "       [-1.28652909e+00],\n",
              "       [ 6.30793383e-02],\n",
              "       [ 6.86337586e-01],\n",
              "       [-5.16330268e-01],\n",
              "       [ 6.07050618e-01],\n",
              "       [-1.24698931e-01],\n",
              "       [-1.04640951e-01],\n",
              "       [-1.49435624e-02],\n",
              "       [ 8.97076730e-02],\n",
              "       [-1.85294875e-01],\n",
              "       [ 2.41144943e-01],\n",
              "       [ 2.80209970e-01],\n",
              "       [ 3.44891939e-01],\n",
              "       [-2.85407560e-01],\n",
              "       [ 1.56915719e-01],\n",
              "       [-4.75050558e-01],\n",
              "       [-2.86930388e-02],\n",
              "       [ 3.68413177e-01],\n",
              "       [ 4.25626008e-02],\n",
              "       [-3.53852912e-01],\n",
              "       [-1.68275670e-01],\n",
              "       [-4.03271230e-02],\n",
              "       [ 2.83946562e-01],\n",
              "       [-4.32342904e-02],\n",
              "       [ 1.84014307e-01],\n",
              "       [ 4.98572988e-02],\n",
              "       [ 1.56199824e-01],\n",
              "       [-2.53274246e-01],\n",
              "       [ 1.16080317e-01],\n",
              "       [ 3.06533644e-02],\n",
              "       [-1.96507463e-01],\n",
              "       [-9.04123037e-02],\n",
              "       [ 8.32570198e-02],\n",
              "       [-1.80624803e-01],\n",
              "       [ 4.59519724e-02],\n",
              "       [ 1.61402123e-02],\n",
              "       [-3.52616182e-03],\n",
              "       [-2.34025015e-01],\n",
              "       [ 4.73602935e-02],\n",
              "       [-1.92843478e-01],\n",
              "       [-1.29724529e-01],\n",
              "       [ 2.63914429e-01],\n",
              "       [ 8.34024275e-02],\n",
              "       [-1.01744085e-01],\n",
              "       [-8.83132434e-02],\n",
              "       [-4.24357045e-02],\n",
              "       [-1.26072009e-02],\n",
              "       [-1.45824887e-01],\n",
              "       [-1.66566070e-02],\n",
              "       [ 1.93778868e-01],\n",
              "       [-1.63752827e-01],\n",
              "       [-2.49266125e-01],\n",
              "       [-4.10310156e-02],\n",
              "       [ 3.65328693e-01],\n",
              "       [-1.88218547e-02],\n",
              "       [-3.26190156e-01],\n",
              "       [ 2.16315050e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xs284OejTilx",
        "colab_type": "text"
      },
      "source": [
        "## **FEATURE ENGINEERING FOR TESTING DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jdgrni-TiIq",
        "colab_type": "code",
        "outputId": "d9bb3bc3-3660-4072-e219-63dd5df9e105",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "! gdown --id '1JnF9biNzFqx5_9RKzCKPKgHPggtDHhue'\n",
        "test = pd.read_csv('./test.csv', encoding = 'big5')\n",
        "test = test.iloc[:, 2:]\n",
        "test[test == 'NR'] = 0\n",
        "test = test.to_numpy()"
      ],
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1JnF9biNzFqx5_9RKzCKPKgHPggtDHhue\n",
            "To: /content/test.csv\n",
            "\r  0% 0.00/197k [00:00<?, ?B/s]\r100% 197k/197k [00:00<00:00, 56.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rk43DF45bWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# noticed that test data lacked the first row of data, which is AMB_TEMP, manually fill them up\n",
        "add = np.empty((1,9))\n",
        "add[0] = [21, 21, 20, 20, 19, 19, 19, 18, 17]\n",
        "test = np.concatenate((add,test), axis = 0)\n",
        "test_x = np.empty([240, 18*9], dtype = float)\n",
        "for i in range(240):\n",
        "    test_x[i, :] = test[18 * i: 18* (i + 1), :].reshape(1, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BK8FCa_4g11a",
        "colab_type": "text"
      },
      "source": [
        "## **NORMALIZATION FOR TESTING DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJ_laKAag0DJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(test_x)):\n",
        "    for j in range(len(test_x[0])):\n",
        "        if std_x[j] != 0:\n",
        "            test_x[i][j] = (test_x[i][j] - mean_x[j]) / std_x[j]\n",
        "normed_test_x = np.concatenate((np.ones([240, 1]), test_x), axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGi6UiEUkYQn",
        "colab_type": "text"
      },
      "source": [
        "## **PREDICTION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txt6tH7MkXwX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_w = np.load('model_weights.npy')\n",
        "ans_y = np.dot(normed_test_x, test_w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toxmjS1IkokP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame(np.empty((240, 2)), index = np.arange(240) + 1, columns = ['id', 'value'])\n",
        "for i in range(240):\n",
        "  df.iloc[i, 0] = 'id_' + str(i)\n",
        "  df.iloc[i,1] = ans_y[i][0]\n",
        "df.to_csv('submission.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}