{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNbEAZex2sKmeZu6z/rraEK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shyDaniel/PM2.5_prediction_regression/blob/master/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7TeA9Q1qt95",
        "colab_type": "text"
      },
      "source": [
        "# **PREDICTING PM2.5 WITH LINEAR REGRESSION, TECHINIQUES INCLUDING FEATURE ENGINEERING, CROSS-VALIDATION, NORMALIZATION, AND ADAGRAD GRADIENT OPTIMIZATION.**\n",
        "\n",
        "Kaggle: https://www.kaggle.com/c/ml2020spring-hw1/overview\n",
        "\n",
        "Hanyu Song 03/19/2020"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYrq3fUsb0tm",
        "colab_type": "code",
        "outputId": "f0b5dab4-8065-4bab-900c-d9e6284e1167",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "# import train and test from google drive\n",
        "! gdown --id '1JnF9biNzFqx5_9RKzCKPKgHPggtDHhue'\n",
        "test = pd.read_csv('./test.csv', encoding = 'big5')\n",
        "! gdown --id '1VR_MKDGwhexEThy4VEZudoN0zKgNRpys'\n",
        "train = pd.read_csv('./train.csv', encoding = 'big5')"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1JnF9biNzFqx5_9RKzCKPKgHPggtDHhue\n",
            "To: /content/test.csv\n",
            "100% 197k/197k [00:00<00:00, 74.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1VR_MKDGwhexEThy4VEZudoN0zKgNRpys\n",
            "To: /content/train.csv\n",
            "100% 466k/466k [00:00<00:00, 61.7MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDLB4UZiHbt2",
        "colab_type": "text"
      },
      "source": [
        "## **FEATURE ENGINEERING FOR TRAINING DATASET**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ApB6JLyuIfc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# delete unnecessary columns, fill in NR values, change to numpy form\n",
        "train = train.iloc[:, 3:]\n",
        "train[train == 'NR'] = 0\n",
        "train_data = train.to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPPZzHpjHfS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now split train data into 12 (months) blocks in which each block contains 18 (features )*480 (24 hours * 20 days) info\n",
        "monthly_train = {}\n",
        "for month in range(12):\n",
        "  temp = np.empty((18, 480))\n",
        "  for day in range(20):\n",
        "    temp[:, day*24 : (day + 1)*24] = train_data[18 * (20*month + day) : 18 * (20 * month + day + 1), :]\n",
        "  monthly_train[month] = temp;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXXJAyfEQJSC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we will use previous 9 hours to data to predict the next, which is the 10th hour of pm2.5 level. \n",
        "# Therefore, out of the 480 hours we have for a given month, we have 471 sets of data (480 - 9) that can be used for training.\n",
        "# y shape: (12*471) * 1\n",
        "# x shape: (12*471) * (9*18)\n",
        "# weight shape: (9*18) * 1\n",
        "# y = x*w\n",
        "\n",
        "x = np.empty((12*471, 9*18), dtype = float)\n",
        "y = np.empty((12*471, 1), dtype = float)\n",
        "\n",
        "for month in range(12):\n",
        "  for day in range(20):\n",
        "    for hour in range(24):\n",
        "      if day == 0 and hour < 9:\n",
        "          continue\n",
        "      y[month * 471 + day * 24 + hour - 9, 0] = monthly_train[month][9, day * 24 + hour] #PM2.5 is on row 9\n",
        "\n",
        "for month in range(12):\n",
        "  for day in range(20):\n",
        "    for hour in range(24):\n",
        "      if day == 19 and hour > 14: \n",
        "        continue\n",
        "      x[month * 471 + day * 24 + hour, :] = monthly_train[month][:, day * 24 + hour : day * 24 + hour + 9].reshape(1, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNP6ekTSHnRr",
        "colab_type": "text"
      },
      "source": [
        "## **NORMALIZATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEzkzU6lF1SZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for each of the 18 features, compute their mean and std \n",
        "# then use newdata = (data - mean) /std to update x\n",
        "mean_x = np.mean(x, axis = 0) #18 * 9 \n",
        "std_x = np.std(x, axis = 0) #18 * 9 \n",
        "normed_x = np.empty(x.shape, dtype = float)\n",
        "for i in range(len(x)): #12 * 471\n",
        "    for j in range(len(x[0])): #18 * 9 \n",
        "        if std_x[j] != 0:\n",
        "            normed_x[i][j] = (x[i][j] - mean_x[j]) / std_x[j]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knF_dm5ha088",
        "colab_type": "text"
      },
      "source": [
        "## **CROSS-VALIDATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6YkjojRaz2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is an illustration of how we would split dataset into 4:1 train and validate\n",
        "# x_train_set = x[: math.floor(len(normed_x) * 0.8), :]\n",
        "# y_train_set = y[: math.floor(len(y) * 0.8), :]\n",
        "# x_validation = x[math.floor(len(normed_x) * 0.8): , :]\n",
        "# y_validation = y[math.floor(len(y) * 0.8): , :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nehvGmDK8d9_",
        "colab_type": "code",
        "outputId": "c856b72d-b0a9-4590-d1ee-17d00063b8a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import math\n",
        "import random as rand\n",
        "\n",
        "dim = 9 * 18 + 1 # 9 * 18 features with 1 more constant\n",
        "learning_rate = 100\n",
        "iter_time = 10000\n",
        "adagrad = np.zeros([dim, 1])\n",
        "eps = 0.0000000001\n",
        "sum_loss = 0\n",
        "k_fold = 5\n",
        "\n",
        "# Do 5-fold cross-validation on the normed_x and y\n",
        "for i in range(k_fold):\n",
        "  w = np.zeros((dim, 1))\n",
        "  # create training and validating data for each iteration\n",
        "  x_train_set = np.concatenate((normed_x[: math.floor(len(normed_x) * (0.2*i)), :], normed_x[math.floor(len(normed_x) * 0.2*(i + 1)) :, :]))\n",
        "  x_validate_set = normed_x[math.floor(len(normed_x) * (0.2*i)) : math.floor(len(normed_x) * 0.2* (i + 1))]\n",
        "  y_train_set = np.concatenate((y[:math.floor(len(y) * (0.2*i)), :], y[math.floor(len(y) * 0.2*(i + 1)):, :]))\n",
        "  y_validate_set = y[math.floor(len(y) * (0.2*i)) : math.floor(len(y) * 0.2* (i + 1))]\n",
        " \n",
        "  # x train plus one row of constant (to test the weight for the constant term)\n",
        "  temp_x = np.concatenate((np.ones((x_train_set.shape[0], 1)), x_train_set), axis = 1)\n",
        "  x_validate_set = np.concatenate((np.ones((x_validate_set.shape[0], 1)), x_validate_set), axis = 1)\n",
        "  gradient = np.zeros((dim, 1))\n",
        "\n",
        "  for t in range(iter_time):\n",
        "    loss = np.sqrt(np.sum(np.power(np.dot(temp_x, w) - y_train_set, 2))/471/12)#rmse\n",
        "    if(t%1000==0):\n",
        "        print(\"  \" + str(t) + \":\" + str(loss))\n",
        "    # gradient descent\n",
        "    gradient = 2 * np.dot(temp_x.transpose(), np.dot(temp_x, w) - y_train_set) #dim*1\n",
        "\n",
        "    # if (gradient){\n",
        "    #     break;\n",
        "    # }\n",
        "\n",
        "    #adagrad gradient optimization\n",
        "    adagrad += gradient ** 2\n",
        "    w = w - learning_rate * gradient / np.sqrt(adagrad + eps)\n",
        "  \n",
        "  final_w += w\n",
        "  print(\"for the \", i,\"th time, the parameter is roughly \", w[rand.randrange(1,18),0])\n",
        "  valid_loss = np.sqrt(np.sum(np.power(np.dot(x_validate_set, w) - y_validate_set, 2))/471/12)\n",
        "  print(\"the loss for the \", i,\"th time validate is \", valid_loss)\n",
        "  sum_loss += valid_loss\n",
        "\n",
        "print('average loss for the 5-fold validation is: ', sum_loss/k_fold)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0:23.191031803732383\n",
            "  1000:5.137467846585117\n",
            "  2000:5.013471278970329\n",
            "  3000:4.983252584388589\n",
            "  4000:4.973801776031307\n",
            "  5000:4.970552490353995\n",
            "  6000:4.969319033100226\n",
            "  7000:4.968777493908696\n",
            "  8000:4.968488356334668\n",
            "  9000:4.9682996659653735\n",
            "for the  0 th time, the parameter is roughly  1.1562716953101948\n",
            "the loss for the  0 th time validate is  2.8254917029891926\n",
            "  0:22.645491701640278\n",
            "  1000:5.10400672452956\n",
            "  2000:5.003220935378245\n",
            "  3000:4.975611900716189\n",
            "  4000:4.9665335977422895\n",
            "  5000:4.963003843471492\n",
            "  6000:4.961296626266485\n",
            "  7000:4.9602632884047395\n",
            "  8000:4.959522157689649\n",
            "  9000:4.958932469077052\n",
            "for the  1 th time, the parameter is roughly  0.031266346959048716\n",
            "the loss for the  1 th time validate is  2.86800810924602\n",
            "  0:25.17146085577053\n",
            "  1000:5.060297149531589\n",
            "  2000:4.968960727766671\n",
            "  3000:4.943072167072916\n",
            "  4000:4.934112601919547\n",
            "  5000:4.93073239873075\n",
            "  6000:4.929324609804323\n",
            "  7000:4.928642959031936\n",
            "  8000:4.9282417241696805\n",
            "  9000:4.927957891395802\n",
            "for the  2 th time, the parameter is roughly  0.5474766220351762\n",
            "the loss for the  2 th time validate is  2.8978593819708673\n",
            "  0:25.566393590914945\n",
            "  1000:5.4267302702378775\n",
            "  2000:5.335623740489092\n",
            "  3000:5.3111047723428655\n",
            "  4000:5.303035998048722\n",
            "  5000:5.300075327610385\n",
            "  6000:5.2988402917021045\n",
            "  7000:5.298222922887728\n",
            "  8000:5.297842165293392\n",
            "  9000:5.297562017614939\n",
            "for the  3 th time, the parameter is roughly  0.7096563582210423\n",
            "the loss for the  3 th time validate is  2.1390616669298566\n",
            "  0:24.36221492236629\n",
            "  1000:5.245349653748834\n",
            "  2000:5.1536642335414875\n",
            "  3000:5.12865951708782\n",
            "  4000:5.12067252873384\n",
            "  5000:5.117872559878739\n",
            "  6000:5.116749854210054\n",
            "  7000:5.116194667237572\n",
            "  8000:5.1158443249399275\n",
            "  9000:5.1155770007019274\n",
            "for the  4 th time, the parameter is roughly  2.5490623216229813\n",
            "the loss for the  4 th time validate is  2.534097371474121\n",
            "average loss for the 5-fold validation is:  2.6529036465220117\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dBshXDetkfm",
        "colab_type": "text"
      },
      "source": [
        "## **TRAINING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZXdK7Aptegk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4993d162-c86d-49f2-ab57-6e403f98d01e"
      },
      "source": [
        "dim = 9 * 18 + 1 # 9 * 18 features with 1 more constant\n",
        "learning_rate = 100\n",
        "iter_time = 100000\n",
        "adagrad = np.zeros([dim, 1])\n",
        "eps = 0.0000000001\n",
        "w = np.zeros([dim, 1])\n",
        "normed_x = np.concatenate((np.ones([12 * 471, 1]), normed_x), axis = 1)\n",
        "\n",
        "for t in range(iter_time):\n",
        "    loss = np.sqrt(np.sum(np.power(np.dot(normed_x, w) - y, 2))/471/12)#rmse\n",
        "    if(t%1000==0):\n",
        "        print(str(t) + \":\" + str(loss))\n",
        "    gradient = 2 * np.dot(normed_x.transpose(), np.dot(normed_x, w) - y) #dim*1\n",
        "    adagrad += gradient ** 2\n",
        "    w = w - learning_rate * gradient / np.sqrt(adagrad + eps)\n",
        "np.save('model_weights.npy', w)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0:27.071214829194115\n",
            "1000:7.0909686439472175\n",
            "2000:6.02412917022559\n",
            "3000:5.786921459274559\n",
            "4000:5.719646593920436\n",
            "5000:5.697327465527851\n",
            "6000:5.6890026614252855\n",
            "7000:5.685550743411822\n",
            "8000:5.683950654084062\n",
            "9000:5.683112196533551\n",
            "10000:5.682612389290917\n",
            "11000:5.68227557001515\n",
            "12000:5.682023846319957\n",
            "13000:5.681820475817497\n",
            "14000:5.681647109858766\n",
            "15000:5.6814940870334425\n",
            "16000:5.6813560499652676\n",
            "17000:5.68122986139529\n",
            "18000:5.681113569134227\n",
            "19000:5.6810058734465585\n",
            "20000:5.680905845208106\n",
            "21000:5.6808127734060685\n",
            "22000:5.680726081059967\n",
            "23000:5.680645278038106\n",
            "24000:5.680569934064305\n",
            "25000:5.680499662904217\n",
            "26000:5.680434112806312\n",
            "27000:5.680372960479074\n",
            "28000:5.680315907092202\n",
            "29000:5.680262675455349\n",
            "30000:5.680213007897699\n",
            "31000:5.68016666457814\n",
            "32000:5.680123422071689\n",
            "33000:5.680083072142897\n",
            "34000:5.6800454206538085\n",
            "35000:5.680010286574953\n",
            "36000:5.679977501079685\n",
            "37000:5.679946906709083\n",
            "38000:5.6799183565985905\n",
            "39000:5.679891713759908\n",
            "40000:5.679866850413115\n",
            "41000:5.679843647364887\n",
            "42000:5.679821993429255\n",
            "43000:5.67980178488782\n",
            "44000:5.679782924986582\n",
            "45000:5.6797653234668655\n",
            "46000:5.679748896127968\n",
            "47000:5.679733564419362\n",
            "48000:5.679719255060442\n",
            "49000:5.67970589968595\n",
            "50000:5.679693434515315\n",
            "51000:5.679681800044319\n",
            "52000:5.679670940757548\n",
            "53000:5.67966080486024\n",
            "54000:5.679651344028208\n",
            "55000:5.679642513174627\n",
            "56000:5.6796342702325235\n",
            "57000:5.679626575951942\n",
            "58000:5.679619393710753\n",
            "59000:5.679612689338214\n",
            "60000:5.679606430950416\n",
            "61000:5.6796005887967995\n",
            "62000:5.679595135116998\n",
            "63000:5.679590044007333\n",
            "64000:5.679585291296268\n",
            "65000:5.679580854428259\n",
            "66000:5.679576712355409\n",
            "67000:5.679572845436405\n",
            "68000:5.679569235342248\n",
            "69000:5.6795658649683345\n",
            "70000:5.679562718352423\n",
            "71000:5.679559780598124\n",
            "72000:5.679557037803535\n",
            "73000:5.679554476994652\n",
            "74000:5.679552086063266\n",
            "75000:5.6795498537090205\n",
            "76000:5.6795477693853575\n",
            "77000:5.679545823249102\n",
            "78000:5.679544006113408\n",
            "79000:5.679542309403882\n",
            "80000:5.679540725117629\n",
            "81000:5.679539245785064\n",
            "82000:5.6795378644342644\n",
            "83000:5.679536574557727\n",
            "84000:5.679535370081342\n",
            "85000:5.679534245335446\n",
            "86000:5.679533195027822\n",
            "87000:5.679532214218502\n",
            "88000:5.679531298296249\n",
            "89000:5.679530442956628\n",
            "90000:5.6795296441815335\n",
            "91000:5.67952889822009\n",
            "92000:5.6795282015708315\n",
            "93000:5.679527550965069\n",
            "94000:5.6795269433513775\n",
            "95000:5.67952637588111\n",
            "96000:5.6795258458948865\n",
            "97000:5.679525350909983\n",
            "98000:5.6795248886085705\n",
            "99000:5.679524456826725\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xs284OejTilx",
        "colab_type": "text"
      },
      "source": [
        "## **FEATURE ENGINEERING FOR TESTING DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jdgrni-TiIq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = test.iloc[:, 2:]\n",
        "test[test == 'NR'] = 0\n",
        "test = test.to_numpy()\n",
        "\n",
        "# noticed that test data lacked the last row of data, which is CH4, manually fill them with 1.7\n",
        "add = np.ones((1,9))\n",
        "for i in range(add.shape[1]):\n",
        "  add[0,i] = 1.7\n",
        "test = np.concatenate((test, add))\n",
        "test_x = np.empty([240, 18*9], dtype = float)\n",
        "for i in range(240):\n",
        "    test_x[i, :] = test[18 * i: 18* (i + 1), :].reshape(1, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BK8FCa_4g11a",
        "colab_type": "text"
      },
      "source": [
        "## **NORMALIZATION FOR TESTING DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJ_laKAag0DJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean_test = np.mean(test_x, axis = 0)\n",
        "std_test = np.std(test_x, axis = 0)\n",
        "normed_test_x = np.empty(test_x.shape, dtype = float)\n",
        "\n",
        "for i in range(len(test_x)):\n",
        "    for j in range(len(test_x[0])):\n",
        "        if std_test[j] != 0:\n",
        "            normed_test_x[i][j] = (test_x[i][j] - mean_test[j]) / std_test[j]\n",
        "normed_test_x = np.concatenate((np.ones([240, 1]), normed_test_x), axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGi6UiEUkYQn",
        "colab_type": "text"
      },
      "source": [
        "## **PREDICTION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txt6tH7MkXwX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4833e9bb-a425-4f62-f337-6beeb12f83a3"
      },
      "source": [
        "test_w = np.load('model_weights.npy')\n",
        "ans_y = np.dot(normed_test_x, test_w)\n",
        "ans_y"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.17980716e+01],\n",
              "       [ 2.40567956e+01],\n",
              "       [ 3.91182932e+01],\n",
              "       [ 2.74206837e+01],\n",
              "       [ 3.32827692e+01],\n",
              "       [ 1.20404011e+01],\n",
              "       [ 1.73540086e+00],\n",
              "       [ 1.11373897e+01],\n",
              "       [ 3.29420529e+01],\n",
              "       [-2.07246583e+01],\n",
              "       [ 2.29510790e+01],\n",
              "       [ 2.15953050e+01],\n",
              "       [ 2.42138181e+01],\n",
              "       [-7.92653083e+00],\n",
              "       [ 1.92617675e+01],\n",
              "       [ 1.45647040e+01],\n",
              "       [ 1.35981073e+01],\n",
              "       [ 5.82723395e+01],\n",
              "       [-4.81168199e+00],\n",
              "       [ 1.68981752e+01],\n",
              "       [ 1.93255854e+01],\n",
              "       [ 8.82347710e+00],\n",
              "       [ 2.97535402e+01],\n",
              "       [ 2.55270178e+01],\n",
              "       [ 2.71937558e+01],\n",
              "       [ 2.05830600e+01],\n",
              "       [ 7.15740994e+00],\n",
              "       [ 8.42083843e+00],\n",
              "       [ 1.21472043e+01],\n",
              "       [-1.28291766e+01],\n",
              "       [ 1.65022314e+01],\n",
              "       [ 6.76819920e+00],\n",
              "       [ 2.23917099e+01],\n",
              "       [ 2.22148320e+01],\n",
              "       [ 1.94947409e+01],\n",
              "       [ 2.65029575e+01],\n",
              "       [ 1.88337417e+01],\n",
              "       [-2.15983959e+00],\n",
              "       [-8.08674682e-01],\n",
              "       [ 2.61759411e+01],\n",
              "       [ 2.54258846e+01],\n",
              "       [ 2.53875126e+01],\n",
              "       [ 2.36179169e+01],\n",
              "       [-1.18144593e+01],\n",
              "       [ 3.08664665e+01],\n",
              "       [ 3.77775616e+01],\n",
              "       [ 1.90892943e+01],\n",
              "       [ 1.15967256e+01],\n",
              "       [ 1.48268559e+01],\n",
              "       [ 3.38071056e+01],\n",
              "       [ 1.84265151e+01],\n",
              "       [ 1.89020405e+01],\n",
              "       [ 5.30949587e+01],\n",
              "       [ 1.16278044e+01],\n",
              "       [ 1.21583284e+01],\n",
              "       [ 3.63577548e+01],\n",
              "       [ 1.48374478e+01],\n",
              "       [ 3.54173262e+01],\n",
              "       [ 1.15454898e+01],\n",
              "       [ 3.07045207e+01],\n",
              "       [ 3.30919753e+01],\n",
              "       [ 4.41167708e+01],\n",
              "       [ 1.09421838e+01],\n",
              "       [ 1.39163329e+01],\n",
              "       [ 1.05483503e+02],\n",
              "       [ 1.38583462e+01],\n",
              "       [ 2.44720281e+01],\n",
              "       [ 1.08794192e+02],\n",
              "       [ 9.82875229e+00],\n",
              "       [ 3.79414366e+01],\n",
              "       [ 1.87673403e+01],\n",
              "       [ 4.06323482e+01],\n",
              "       [ 2.98197735e+01],\n",
              "       [ 1.58784010e+01],\n",
              "       [ 3.04691733e+01],\n",
              "       [ 1.17207043e+01],\n",
              "       [ 3.75069014e+01],\n",
              "       [ 6.25510423e+00],\n",
              "       [ 3.36977876e+01],\n",
              "       [ 2.88411840e+01],\n",
              "       [ 2.86664339e+01],\n",
              "       [ 7.05599258e+00],\n",
              "       [ 3.04032955e+01],\n",
              "       [ 1.29151505e+01],\n",
              "       [ 1.90551873e+01],\n",
              "       [ 4.03565193e+00],\n",
              "       [ 1.65494978e+01],\n",
              "       [ 2.29932864e+01],\n",
              "       [ 2.58422576e+01],\n",
              "       [ 3.20988995e+01],\n",
              "       [ 1.76618083e+01],\n",
              "       [ 1.74264854e+01],\n",
              "       [-1.14822939e+02],\n",
              "       [ 3.11430086e+00],\n",
              "       [ 2.11961337e+01],\n",
              "       [ 1.73621735e+01],\n",
              "       [ 1.78257146e+01],\n",
              "       [ 1.77521319e+01],\n",
              "       [ 3.15915110e+00],\n",
              "       [-4.35773172e-01],\n",
              "       [ 1.78095639e+01],\n",
              "       [ 2.96616729e+01],\n",
              "       [ 2.09817136e+01],\n",
              "       [ 3.49650709e+00],\n",
              "       [ 2.29258913e+01],\n",
              "       [ 2.38492272e+01],\n",
              "       [ 1.16476905e+01],\n",
              "       [ 2.16560129e+01],\n",
              "       [ 1.16926314e+01],\n",
              "       [ 5.05789894e+01],\n",
              "       [ 2.95732756e+01],\n",
              "       [ 7.91422291e+00],\n",
              "       [ 3.28160067e+01],\n",
              "       [ 1.49112614e+01],\n",
              "       [ 1.66235456e+01],\n",
              "       [ 2.83055072e+01],\n",
              "       [ 1.86874956e+01],\n",
              "       [ 2.21291985e+01],\n",
              "       [ 3.25067528e+01],\n",
              "       [ 1.35300570e+01],\n",
              "       [ 4.02128408e+00],\n",
              "       [ 2.04034407e+01],\n",
              "       [ 1.91492473e+01],\n",
              "       [ 1.11534909e+01],\n",
              "       [ 1.58723520e+01],\n",
              "       [ 2.32646580e+01],\n",
              "       [ 2.39112087e+01],\n",
              "       [ 3.24428111e+01],\n",
              "       [ 1.19679301e+01],\n",
              "       [-1.49984729e+01],\n",
              "       [ 1.60191495e+01],\n",
              "       [ 5.07849987e+00],\n",
              "       [ 2.57825433e+01],\n",
              "       [ 2.25305840e+01],\n",
              "       [ 2.37920901e+01],\n",
              "       [ 3.04180476e+00],\n",
              "       [ 1.42074853e+00],\n",
              "       [ 2.51826815e+01],\n",
              "       [ 5.61602788e+00],\n",
              "       [ 3.18271093e+01],\n",
              "       [ 2.67132378e+01],\n",
              "       [ 3.09783511e+01],\n",
              "       [ 3.35171891e+01],\n",
              "       [ 4.55875506e+00],\n",
              "       [ 1.90000819e+01],\n",
              "       [ 1.73407715e+01],\n",
              "       [ 2.84724305e+01],\n",
              "       [-6.18415233e-02],\n",
              "       [ 1.88561233e+01],\n",
              "       [ 7.52985064e+00],\n",
              "       [ 1.39282254e+01],\n",
              "       [ 1.72280542e+01],\n",
              "       [ 2.55902260e+01],\n",
              "       [ 3.69207035e+01],\n",
              "       [ 3.17059671e+01],\n",
              "       [ 2.07881802e+01],\n",
              "       [ 2.28453226e+01],\n",
              "       [ 2.40765977e+01],\n",
              "       [ 2.44286181e+01],\n",
              "       [ 3.70121923e+00],\n",
              "       [ 8.05956849e+00],\n",
              "       [ 2.71801389e+01],\n",
              "       [ 2.55827476e+01],\n",
              "       [-2.03553049e-01],\n",
              "       [ 2.23245434e+01],\n",
              "       [ 2.94895096e+01],\n",
              "       [ 2.26794689e+02],\n",
              "       [ 3.26980756e+01],\n",
              "       [ 4.52924977e+01],\n",
              "       [ 1.39573146e+01],\n",
              "       [ 2.34412093e+01],\n",
              "       [ 1.99058571e+01],\n",
              "       [ 1.97825495e+01],\n",
              "       [ 3.81617344e+01],\n",
              "       [ 8.53723723e+00],\n",
              "       [ 2.64387005e+01],\n",
              "       [ 2.23497897e+01],\n",
              "       [ 2.39335677e+01],\n",
              "       [ 1.64496962e+01],\n",
              "       [ 2.89890772e+00],\n",
              "       [ 2.10390705e+01],\n",
              "       [ 5.88965795e+00],\n",
              "       [ 1.81385601e+01],\n",
              "       [ 2.36047172e+01],\n",
              "       [ 2.41777681e+01],\n",
              "       [ 2.29182760e+01],\n",
              "       [ 3.54763477e+01],\n",
              "       [ 2.74487329e+01],\n",
              "       [ 1.40918558e+01],\n",
              "       [ 1.09883363e+00],\n",
              "       [ 2.04419417e+01],\n",
              "       [ 1.38729233e+01],\n",
              "       [ 2.23029308e+01],\n",
              "       [ 4.01835800e+01],\n",
              "       [-1.53978124e+01],\n",
              "       [ 9.12644844e+00],\n",
              "       [ 2.50348137e+01],\n",
              "       [ 3.48213876e+01],\n",
              "       [ 3.71677154e+01],\n",
              "       [ 5.12257530e+01],\n",
              "       [ 2.08809146e+01],\n",
              "       [ 3.76314403e+01],\n",
              "       [ 5.52747857e+00],\n",
              "       [ 3.85963126e+00],\n",
              "       [ 2.15991312e+01],\n",
              "       [ 2.80185630e+01],\n",
              "       [ 1.59420391e+01],\n",
              "       [ 1.29374126e+01],\n",
              "       [ 4.65087611e+01],\n",
              "       [ 2.92327956e+01],\n",
              "       [ 2.68041609e+01],\n",
              "       [ 3.29025356e+01],\n",
              "       [ 1.57354197e+01],\n",
              "       [ 2.30474003e+01],\n",
              "       [ 2.08127326e+01],\n",
              "       [ 3.55408645e+01],\n",
              "       [ 1.48847884e+01],\n",
              "       [ 2.03214148e+01],\n",
              "       [ 2.03934119e+01],\n",
              "       [ 2.32276102e+01],\n",
              "       [ 1.91461612e+01],\n",
              "       [ 1.98006596e+01],\n",
              "       [ 3.11100605e+01],\n",
              "       [ 3.17790774e+01],\n",
              "       [ 4.67944163e+00],\n",
              "       [ 2.25026235e+01],\n",
              "       [ 3.42232056e+01],\n",
              "       [ 1.26707460e+02],\n",
              "       [ 4.14387782e+00],\n",
              "       [-2.64921047e+01],\n",
              "       [ 2.16770402e+01],\n",
              "       [ 3.51376060e+01],\n",
              "       [ 1.30816096e+01],\n",
              "       [ 1.99663005e+01],\n",
              "       [ 2.08551498e+01],\n",
              "       [ 3.09592069e+00],\n",
              "       [ 2.15813179e+01],\n",
              "       [ 4.14637591e+01],\n",
              "       [ 1.80768415e+01],\n",
              "       [ 3.58042177e+01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toxmjS1IkokP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame(np.empty((240, 2)), index = np.arange(240) + 1, columns = ['id', 'value'])\n",
        "for i in range(240):\n",
        "  df.iloc[i, 0] = 'id_' + str(i)\n",
        "df.iloc[:, 1] = ans_y\n",
        "df.to_csv('submission.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}